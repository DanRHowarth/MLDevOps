{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## MLFlow Fundamentals\n",
    "* See slide deck for schematic overview"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0. Core idea\n",
    "* code is packaged in a MLFLow (wrapper/object, etc.)\n",
    "* challenge it therefore to package it correctly:\n",
    "    * conda environment set-up (we can also use docker if we want to)\n",
    "    * the project description and commands are set-up\n",
    "* this way, we can execute our projects successfully\n",
    "*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Example of building an MLFLow Component\n",
    "* A python script `download_data.py` can be run from the command line like this:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "python download_data.py \\\n",
    "       --file_url https://raw.githubusercontent.com/scikit-learn/scikit-learn/4dfdfb4e1bb3719628753a4ece995a1b2fa5312a/sklearn/datasets/data/iris.csv \\\n",
    "       --artifact_name iris \\\n",
    "       --artifact_type raw_data \\\n",
    "       --artifact_description \"The sklearn IRIS dataset\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* To run via MLFLow, it needs a env file - `conda.yml`:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name: download_data\n",
    "channels:\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - requests=2.24.0\n",
    "  - pip=20.3.3\n",
    "  - pip:\n",
    "      - wandb==0.10.21"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* and a project file, `MLproject`:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name: download_data\n",
    "conda_env: conda.yml\n",
    "\n",
    "entry_points:\n",
    "  main:\n",
    "    parameters:\n",
    "      file_url:\n",
    "        description: URL of the file to download\n",
    "        type: uri\n",
    "      artifact_name:\n",
    "        description: Name for the W&B artifact that will be created\n",
    "        type: str\n",
    "      artifact_type:\n",
    "        description: Type of the artifact to create\n",
    "        type: str\n",
    "        default: raw_data\n",
    "      artifact_description:\n",
    "        description: Description for the artifact\n",
    "        type: str\n",
    "\n",
    "    command: >-\n",
    "      python download_data.py --file_url {file_url} \\\n",
    "                              --artifact_name {artifact_name} \\\n",
    "                              --artifact_type {artifact_type} \\\n",
    "                              --artifact_description {artifact_description}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* it can then be run from the command like as follows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# here . is used assuming the script to run is in our current directory\n",
    "mlflow . -P file_url={file_url} \\\n",
    "        -P artifact_name={artifact_name} \\\n",
    "        -P artifact_type={artifact_type} \\\n",
    "        -P artifact_description={artifact_description}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Running an MLFLow project - options"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mlflow run to filepath of project code\n",
    "\n",
    "mlflow run /path/to/the/local/folder\n",
    "\n",
    "mlflow run git@github.com/my_username/my_repo.git"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Parameters are specified using -P [parameter_name]=[parameter value]. specify one -P option for each parameter\n",
    "mlflow run ./my_project -P file_url=https://myurl.com -P artifact_name=my-artifact"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# -e for a different entry point to main\n",
    "mlflow run ./my_project -e other_script _P parameter=value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# -v to specify a specifc release\n",
    "mlflow run git@github.com/my_username/my_repo.git -v 1.2.3 \\\n",
    "            -P file_url=https://myurl.com \\\n",
    "            -P artifact_name=my-artifact"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Linking components into a pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Pipeline is implemented in MLFlow as an MLFlow project that calls other MLFlow projects\n",
    "    * The main.py of the 'control project' calls the other MLFlow projects\n",
    "    * The control project has a env and a ML Project project description\n",
    "* We use mlflow.run in the main script - this calls our sub-projects\n",
    "    * Q: by using mlflow.run, it looks like we sacrifice some flexibility in what entry points can be called - these need to be predefined up front (?)\n",
    "*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# example of mlflow.run and how it compares to a command line implementation\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.run(\n",
    "  # URI can be a local path or the URL to a git repository\n",
    "  # here we are going to use a local path\n",
    "  uri=\"my_project\",\n",
    "  # Entry point to call\n",
    "  entry_point=\"main\",           ## this value here is where i think it gets more specific\n",
    "  # Parameters for that entry point\n",
    "  parameters={\n",
    "    \"file_url\": \"https://...\",\n",
    "    \"artifact_name\": \"my_data.csv\"\n",
    "  }\n",
    ")\n",
    "\n",
    "# equivalent to\n",
    "\n",
    "! mlflow run my_project -e main -P file_url=\"https://...\" -P artifact_name=\"my_data.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# a main.py script could look like this\n",
    "## need to understand what uri is here - think its the name of the sub mlflow project\n",
    "\n",
    "# mlflow.run implements the project description in the same way as the CL\n",
    "# So each mlflow.run runs the component via the project description\n",
    "\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.run(\n",
    "  uri=\"download_data\",\n",
    "  entry_point=\"main\",\n",
    "  parameters={\n",
    "    \"file_url\": \"https://...\",\n",
    "    \"output_artifact\": \"raw_data.csv\"\n",
    "  }\n",
    ")\n",
    "\n",
    "mlflow.run(\n",
    "  uri=\"remove_duplicates\",\n",
    "  entry_point=\"main\",\n",
    "  parameters={\n",
    "    \"input_artifact\": \"raw_data.csv:latest\",\n",
    "    \"output_artifact\": \"clean_data.csv\"\n",
    "  }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* to note - we can turn this file into something that is usable on the CL - we would add a def go function and insert the relevant arg.parse parameters.\n",
    "* This thenm is what hydra will do"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Hydra"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* we can set up a hydra config file that enables us to set parameters in main.py from the command line (need to verify these last two elements)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# example config file\n",
    "main:\n",
    "  project_name: my_project\n",
    "  experiment_name: dev\n",
    "data:\n",
    "  train_data: \"exercise_6/data_train.csv:latest\"\n",
    "random_forest_pipeline:\n",
    "  random_forest:\n",
    "    n_estimators: 100\n",
    "    criterion: gini\n",
    "    max_depth: null"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the config file sets up the use of using different parameters by hydra\n",
    "\n",
    "# we need to import hydra and add the hydra decorator, referencing the name of our config file\n",
    "import mlflow\n",
    "import hydra\n",
    "\n",
    "@hydra.main(config_name=\"config\")\n",
    "def go(config):\n",
    "  # Now here config is a dictionary with our configuration\n",
    "  # For example, to access the parameter train_data in the data\n",
    "  # section we can just do\n",
    "  train_data = config[\"data\"][\"train_data\"]\n",
    "\n",
    "  ...\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "  go()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# finally, we update our MLFlow project description file to accomdate hydra\n",
    "\n",
    "name: main\n",
    "conda_env: conda.yml\n",
    "\n",
    "entry_points:\n",
    "  main:\n",
    "    parameters:\n",
    "      hydra_options:                                ## here\n",
    "        description: Hydra parameters to override\n",
    "        type: str\n",
    "        default: ''\n",
    "    command: >-\n",
    "      python main.py $(echo {hydra_options})        ## here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* How hydra overrides parameters and runs from the command line"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# examples\n",
    "\n",
    "mlflow run [path or URL to the pipeline] \\\n",
    "       -P hydra_options=\"main.experiment_name=my_experiment\"\n",
    "\n",
    "mlflow run [path or URL to the pipeline] \\\n",
    "       -P hydra_options=\"random_forest.random_forest_pipeline.n_estimators=50\"\n",
    "\n",
    "mlflow run [path or URL to the pipeline] \\\n",
    "       -P hydra_options=\"main.experiment_name=my_experiment main.project_name=test\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Organising pipeline so that it is tracked with W&B"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#  ensures that the pipeline is grouped together in one single experiment within the appropriate project.\n",
    "\n",
    "# NOTE: this will only work if the components do NOT set the experiment name and the project on their own when calling wandb.init.\n",
    "\n",
    "import hydra\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "@hydra.main(config_name=\"config\")\n",
    "def go(config):\n",
    "\n",
    "  os.environ[\"WANDB_PROJECT\"] = config[\"main\"][\"project_name\"]\n",
    "  os.environ[\"WANDB_RUN_GROUP\"] = config[\"main\"][\"experiment_name\"]\n",
    "\n",
    "  mlflow.run(\n",
    "    ...\n",
    "  )\n",
    "\n",
    "  ...\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  go()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# here is another example with root path added - apparently needed\n",
    "\n",
    "import mlflow\n",
    "import os\n",
    "import wandb\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "\n",
    "# This automatically reads in the configuration\n",
    "@hydra.main(config_name='config')\n",
    "def go(config: DictConfig):\n",
    "\n",
    "    # Setup the wandb experiment. All runs will be grouped under this name\n",
    "    os.environ[\"WANDB_PROJECT\"] = config[\"main\"][\"project_name\"]\n",
    "    os.environ[\"WANDB_RUN_GROUP\"] = config[\"main\"][\"experiment_name\"]\n",
    "\n",
    "    # You can get the path at the root of the MLflow project with this:\n",
    "    root_path = hydra.utils.get_original_cwd()\n",
    "\n",
    "    _ = mlflow.run(\n",
    "        os.path.join(root_path, \"download_data\"),\n",
    "        \"main\",\n",
    "        parameters={\n",
    "            \"file_url\": config[\"data\"][\"file_url\"],\n",
    "            \"artifact_name\": \"iris.csv\",\n",
    "            \"artifact_type\": \"raw_data\",\n",
    "            \"artifact_description\": \"Input data\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    _ = mlflow.run(\n",
    "        os.path.join(root_path, \"process_data\"),\n",
    "        \"main\",\n",
    "        parameters={\n",
    "            \"input_artifact\": \"iris.csv:latest\",\n",
    "            \"artifact_name\": \"clean_data.csv\",\n",
    "            \"artifact_type\": \"processed_data\",\n",
    "            \"artifact_description\": \"Cleaned data\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    go()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}